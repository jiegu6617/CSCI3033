{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"cnn.ipynb","provenance":[],"mount_file_id":"1J7Y6HEjGfULsHOHxnxG-DUKvhh8aYCJ2","authorship_tag":"ABX9TyOX7X39igyA05XsdR0u2owS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"TsvzhNvJxx_w"},"source":["import numpy as np\n","np.random.seed(2016)\n","\n","import os\n","import glob\n","import cv2\n","import math\n","import pickle\n","import datetime\n","import pandas as pd\n","import statistics\n","import random\n","import time\n","\n","from sklearn.model_selection import train_test_split\n","from sklearn.model_selection import KFold\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Activation, Flatten\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D\n","from keras.optimizers import SGD, Adam\n","from keras.utils import np_utils\n","from keras.models import model_from_json\n","from sklearn.metrics import log_loss\n","import scipy.misc\n","# from scipy.misc import imread, imresize\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"C5KAcOA01i05"},"source":["import os\n","import time\n","import pickle\n","import numpy as np\n","\n","from keras.models import Sequential\n","from keras.optimizers import Adam\n","from keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n","from keras.layers.core import Dense, Activation, Flatten, Dropout\n","from keras.layers.convolutional import Convolution2D\n","from keras.layers.normalization import BatchNormalization\n","\n","from sklearn.metrics import log_loss\n","# from sklearn.cross_validation import LabelShuffleSplit"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LyuX8oTIx0Jb"},"source":["import pickle\n","import datetime\n","import pandas as pd\n","\n","from keras.models import Sequential\n","from keras.layers.core import Dense, Dropout, Flatten\n","from keras.layers.convolutional import Convolution2D, MaxPooling2D, \\\n","                                       ZeroPadding2D\n","\n","# from keras.layers.normalization import BatchNormalization\n","# from keras.optimizers import Adam\n","from keras.optimizers import SGD\n","from keras.utils import np_utils\n","from keras.models import model_from_json\n","# from sklearn.metrics import log_loss\n","from numpy.random import permutation"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N9LYzseKyG2g"},"source":["def cnn():\n","  model = models.Sequential()\n","\n","  ## CNN 1\n","  model.add(Conv2D(32,(3,3),activation='relu',input_shape=(240,240,1)))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(32,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization(axis = 3))\n","  model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  model.add(Dropout(0.2))\n","\n","  ## CNN 2\n","  model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(64,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization(axis = 3))\n","  model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  model.add(Dropout(0.3))\n","\n","  ## CNN 3\n","  model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Conv2D(128,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization(axis = 3))\n","  model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  model.add(Dropout(0.5))\n","\n","  ## CNN 3\n","  #model.add(Conv2D(256,(5,5),activation='relu',padding='same'))\n","  #model.add(BatchNormalization(axis = 3))\n","  #model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  #model.add(Dropout(0.5))\n","\n","  ## Dense & Output\n","  model.add(Flatten())\n","  model.add(Dense(units = 512,activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","  model.add(Dense(units = 128,activation='relu'))\n","  model.add(Dropout(0.5))\n","  model.add(Dense(10,activation='softmax'))\n","\n","  model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n","  return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"diqxG3ybzXWm"},"source":["use_cache = 1\n","# color type: 1 - grey, 3 - rgb\n","color_type_global = 1\n","# color_type = 1 - gray\n","# color_type = 3 - RGB\n","def get_im_cv2(path, img_rows, img_cols, color_type=1):\n","    # Load as grayscale\n","    if color_type == 1:\n","        img = cv2.imread(path, 0)\n","    elif color_type == 3:\n","        img = cv2.imread(path)\n","    # Reduce size\n","    resized = cv2.resize(img, (img_cols, img_rows))\n","    return resized\n","\n","\n","def get_im_cv2_mod(path, img_rows, img_cols, color_type=1):\n","    # Load as grayscale\n","    if color_type == 1:\n","        img = cv2.imread(path, 0)\n","    else:\n","        img = cv2.imread(path)\n","    # Reduce size\n","    rotate = random.uniform(-10, 10)\n","    M = cv2.getRotationMatrix2D((img.shape[1]/2, img.shape[0]/2), rotate, 1)\n","    img = cv2.warpAffine(img, M, (img.shape[1], img.shape[0]))\n","    resized = cv2.resize(img, (img_cols, img_rows), cv2.INTER_LINEAR)\n","    return resized\n","    \n","\n","def get_driver_data():\n","    dr = dict()\n","    # path = os.path.join('..', 'input', 'driver_imgs_list.csv')\n","    path='/content/drive/MyDrive/deep_learning_project/input/driver_imgs_list.csv'\n","    print('Read drivers data')\n","    f = open(path, 'r')\n","    line = f.readline()\n","    while (1):\n","        line = f.readline()\n","        if line == '':\n","            break\n","        arr = line.strip().split(',')\n","        dr[arr[2]] = arr[0]\n","    f.close()\n","    return dr\n","\n","\n","def load_train(img_rows, img_cols, color_type=1):\n","    X_train = []\n","    y_train = []\n","    driver_id = []\n","    start_time = time.time()\n","    driver_data = get_driver_data()\n","\n","\n","\n","    print('Read train images')\n","    for j in range(10):\n","        print('Load folder c{}'.format(j))\n","        path='/content/drive/MyDrive/deep_learning_project/input/train/c'+str(j)+'/*.jpg'\n","        files = glob.glob(path)\n","        i=0\n","        for fl in files:\n","          flbase = os.path.basename(fl)\n","          img = get_im_cv2_mod(fl, img_rows, img_cols, color_type=1)\n","          print('Loading image{}'.format(i))\n","          i = i+1\n","          X_train.append(img)\n","          y_train.append(j)\n","          driver_id.append(driver_data[flbase])\n","\n","    print('Read train data time: {} seconds'.format(round(time.time() - start_time, 2)))\n","    unique_drivers = sorted(list(set(driver_id)))\n","    print('Unique drivers: {}'.format(len(unique_drivers)))\n","    print(unique_drivers)\n","    return X_train, y_train, driver_id, unique_drivers\n","\n","\n","def load_test(img_rows, img_cols, color_type=1):\n","    print('Read test images')\n","    start_time = time.time()\n","    # path = os.path.join('..', 'input', 'test', '*.jpg')\n","    path='/content/drive/MyDrive/deep_learning_project/input/test/*.jpg'\n","    files = glob.glob(path)\n","    X_test = []\n","    X_test_id = []\n","    total = 0\n","    thr = math.floor(len(files)/10)\n","    for fl in files:\n","        flbase = os.path.basename(fl)\n","        img = get_im_cv2_mod(fl, img_rows, img_cols, color_type)\n","        X_test.append(img)\n","        X_test_id.append(flbase)\n","        total += 1\n","        if total%thr == 0:\n","            print('Read {} images from {}'.format(total, len(files)))\n","    \n","    print('Read test data time: {} seconds'.format(round(time.time() - start_time, 2)))\n","    return X_test, X_test_id\n","\n","\n","def cache_data(data, path):\n","    if os.path.isdir(os.path.dirname(path)):\n","        file = open(path, 'wb')\n","        pickle.dump(data, file)\n","        file.close()\n","    else:\n","        print('Directory doesnt exists')\n","\n","\n","def restore_data(path):\n","    data = dict()\n","    if os.path.isfile(path):\n","        file = open(path, 'rb')\n","        data = pickle.load(file)\n","    return data\n","\n","\n","def save_model(model):\n","    json_string = model.to_json()\n","    if not os.path.isdir('cache'):\n","        os.mkdir('cache')\n","    open(os.path.join('cache', 'architecture.json'), 'w').write(json_string)\n","    model.save_weights(os.path.join('cache', 'model_weights.h5'), overwrite=True)\n","\n","\n","def read_model():\n","    model = model_from_json(open(os.path.join('cache', 'architecture.json')).read())\n","    model.load_weights(os.path.join('cache', 'model_weights.h5'))\n","    return model\n","\n","\n","def split_validation_set(train, target, test_size):\n","    random_state = 51\n","    X_train, X_test, y_train, y_test = train_test_split(train, target, test_size=test_size, random_state=random_state)\n","    return X_train, X_test, y_train, y_test\n","\n","\n","def create_submission(predictions, test_id, info):\n","    result1 = pd.DataFrame(predictions, columns=['c0', 'c1', 'c2', 'c3', 'c4', 'c5', 'c6', 'c7', 'c8', 'c9'])\n","    result1.loc[:, 'img'] = pd.Series(test_id, index=result1.index)\n","    now = datetime.datetime.now()\n","    if not os.path.isdir('subm'):\n","        os.mkdir('subm')\n","    suffix = info + '_' + str(now.strftime(\"%Y-%m-%d-%H-%M\"))\n","    sub_file = os.path.join('subm', 'submission_' + suffix + '.csv')\n","    result1.to_csv(sub_file, index=False)\n","\n","\n","def read_and_normalize_train_data(img_rows, img_cols, color_type=1):\n","    cache_path = os.path.join('cache', 'train_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n","    if not os.path.isfile(cache_path) or use_cache == 0:\n","        train_data, train_target, driver_id, unique_drivers = load_train(img_rows, img_cols, color_type)\n","        cache_data((train_data, train_target, driver_id, unique_drivers), cache_path)\n","    else:\n","        print('Restore train from cache!')\n","        (train_data, train_target, driver_id, unique_drivers) = restore_data(cache_path)\n","\n","    train_data = np.array(train_data, dtype=np.uint8)\n","    train_target = np.array(train_target, dtype=np.uint8)\n","    train_data = train_data.reshape(train_data.shape[0], color_type, img_rows, img_cols)\n","    train_target = np_utils.to_categorical(train_target, 10)\n","    train_data = train_data.astype('float32')\n","    train_data /= 255\n","    print('Train shape:', train_data.shape)\n","    print(train_data.shape[0], 'train samples')\n","    return train_data, train_target, driver_id, unique_drivers\n","\n","\n","def read_and_normalize_test_data(img_rows, img_cols, color_type=1):\n","    cache_path = os.path.join('cache', 'test_r_' + str(img_rows) + '_c_' + str(img_cols) + '_t_' + str(color_type) + '.dat')\n","    if not os.path.isfile(cache_path) or use_cache == 0:\n","        test_data, test_id = load_test(img_rows, img_cols, color_type)\n","        cache_data((test_data, test_id), cache_path)\n","    else:\n","        print('Restore test from cache!')\n","        (test_data, test_id) = restore_data(cache_path)\n","\n","    test_data = np.array(test_data, dtype=np.uint8)\n","    test_data = test_data.reshape(test_data.shape[0], color_type, img_rows, img_cols)\n","    test_data = test_data.astype('float32')\n","    test_data /= 255\n","    print('Test shape:', test_data.shape)\n","    print(test_data.shape[0], 'test samples')\n","    return test_data, test_id\n","\n","\n","def dict_to_list(d):\n","    ret = []\n","    for i in d.items():\n","        ret.append(i[1])\n","    return ret\n","\n","\n","def merge_several_folds_mean(data, nfolds):\n","    a = np.array(data[0])\n","    for i in range(1, nfolds):\n","        a += np.array(data[i])\n","    a /= nfolds\n","    return a.tolist()\n","\n","\n","def merge_several_folds_geom(data, nfolds):\n","    a = np.array(data[0])\n","    for i in range(1, nfolds):\n","        a *= np.array(data[i])\n","    a = np.power(a, 1/nfolds)\n","    return a.tolist()\n","\n","\n","def copy_selected_drivers(train_data, train_target, driver_id, driver_list):\n","    data = []\n","    target = []\n","    index = []\n","    for i in range(len(driver_id)):\n","        if driver_id[i] in driver_list:\n","            data.append(train_data[i])\n","            target.append(train_target[i])\n","            index.append(i)\n","    data = np.array(data, dtype=np.float32)\n","    target = np.array(target, dtype=np.float32)\n","    index = np.array(index, dtype=np.uint32)\n","    return data, target, index"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dTAO8WFRxsXD"},"source":["def vgg_bn(img_rows, img_cols, color_type=1):\n","    model = Sequential()\n","    model.add(Convolution2D(32, 3, 3, padding='same', kernel_initializer='he_normal', input_shape=(color_type, img_rows, img_cols)))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Convolution2D(32, 3, 3, padding='same', kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Convolution2D(64, 3, 3, subsample=(2, 2),kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Convolution2D(64, 3, 3, padding='same', kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Convolution2D(128, 3, 3,  subsample=(2, 2),kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Convolution2D(128, 3, 3, padding='same', kernel_initializer='he_normal'))\n","    model.add(BatchNormalization())\n","    model.add(Activation('relu'))\n","    model.add(Flatten())\n","    model.add(Dense(128, activation='sigmoid', kernel_initializer='he_normal'))\n","    model.add(Dropout(0.5))\n","    model.add(Dense(10, activation='softmax', kernel_initializer='he_normal'))\n","    model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n","    return model"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_oDC2MONV0R9","executionInfo":{"status":"ok","timestamp":1620316066927,"user_tz":-480,"elapsed":1784,"user":{"displayName":"Fan Zhang","photoUrl":"","userId":"15762842342010003616"}}},"source":["def cnn(img_rows, img_cols, color_type=1):\n","  model = Sequential()\n","\n","  ## CNN 1\n","  model.add(Convolution2D(32,(3,3),activation='relu',input_shape=(color_type, img_rows, img_cols)))\n","  model.add(BatchNormalization())\n","  model.add(Convolution2D(32,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization(axis = 3))\n","  model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  model.add(Dropout(0.2))\n","\n","  ## CNN 2\n","  model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Convolution2D(64,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization(axis = 3))\n","  model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  model.add(Dropout(0.3))\n","\n","  ## CNN 3\n","  model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization())\n","  model.add(Convolution2D(128,(3,3),activation='relu',padding='same'))\n","  model.add(BatchNormalization(axis = 3))\n","  model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  model.add(Dropout(0.5))\n","\n","  ## CNN 3\n","  #model.add(Conv2D(256,(5,5),activation='relu',padding='same'))\n","  #model.add(BatchNormalization(axis = 3))\n","  #model.add(MaxPooling2D(pool_size=(2,2),padding='same'))\n","  #model.add(Dropout(0.5))\n","\n","  ## Dense & Output\n","  model.add(Flatten())\n","  model.add(Dense(units = 512,activation='relu'))\n","  model.add(BatchNormalization())\n","  model.add(Dropout(0.5))\n","  model.add(Dense(units = 128,activation='relu'))\n","  model.add(Dropout(0.5))\n","\n","\n","  model.add(Dense(10, activation='softmax', kernel_initializer='he_normal'))\n","  model.compile(Adam(lr=1e-3), loss='categorical_crossentropy', metrics=['accuracy'])\n","\n","  return model"],"execution_count":36,"outputs":[]},{"cell_type":"code","metadata":{"id":"gibrMVY1ytcA"},"source":["train_data=np.load('/content/drive/MyDrive/deep_learning_project/train_data.npy')\n","train_target=np.load('/content/drive/MyDrive/deep_learning_project/train_target.npy')\n","unique_drivers=np.load('/content/drive/MyDrive/deep_learning_project/unique_drivers.npy')\n","driver_id=np.load('/content/drive/MyDrive/deep_learning_project/driver_id.npy')\n","test_data=np.load('/content/drive/MyDrive/deep_learning_project/test_data_sub.npy')\n","test_id=np.load('/content/drive/MyDrive/deep_learning_project/test_id_sub.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":633},"id":"LVZpgEk9ydrV","executionInfo":{"status":"error","timestamp":1620316070002,"user_tz":-480,"elapsed":1504,"user":{"displayName":"Fan Zhang","photoUrl":"","userId":"15762842342010003616"}},"outputId":"085377a6-3de5-4923-eac4-112dcbff7695"},"source":["def run_single():\n","    # input image dimensions\n","    img_rows, img_cols = 64, 64\n","    batch_size = 32\n","    nb_epoch = 100\n","    random_state = 51\n","\n","\n","    yfull_train = dict()\n","    yfull_test = []\n","    unique_list_train = ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024',\n","                     'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049',\n","                     'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072',\n","                     'p075']\n","    X_train, Y_train, train_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_train)\n","    unique_list_valid = ['p081']\n","    X_valid, Y_valid, test_index = copy_selected_drivers(train_data, train_target, driver_id, unique_list_valid)\n","\n","    print('Start Single Run')\n","    print('Split train: ', len(X_train), len(Y_train))\n","    print('Split valid: ', len(X_valid), len(Y_valid))\n","    print('Train drivers: ', unique_list_train)\n","    print('Test drivers: ', unique_list_valid)\n","\n","    model = cnn(img_rows, img_cols, color_type_global)\n","    model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch\n","              ,verbose=1, validation_data=(X_valid, Y_valid))\n","run_single()"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Start Single Run\n","Split train:  21601 21601\n","Split valid:  823 823\n","Train drivers:  ['p002', 'p012', 'p014', 'p015', 'p016', 'p021', 'p022', 'p024', 'p026', 'p035', 'p039', 'p041', 'p042', 'p045', 'p047', 'p049', 'p050', 'p051', 'p052', 'p056', 'p061', 'p064', 'p066', 'p072', 'p075']\n","Test drivers:  ['p081']\n"],"name":"stdout"},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1852\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1853\u001b[0;31m     \u001b[0mc_op\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpywrap_tf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_FinishOperation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop_desc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mInvalidArgumentError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_11/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_11/Conv2D/ReadVariableOp)' with input shapes: [?,1,64,64], [3,3,64,32].","\nDuring handling of the above exception, another exception occurred:\n","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-37-b1a23cf53029>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m     model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch\n\u001b[1;32m     27\u001b[0m               ,verbose=1, validation_data=(X_valid, Y_valid))\n\u001b[0;32m---> 28\u001b[0;31m \u001b[0mrun_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-37-b1a23cf53029>\u001b[0m in \u001b[0;36mrun_single\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Test drivers: '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munique_list_valid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolor_type_global\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     model.fit(X_train, Y_train, batch_size=batch_size, epochs=nb_epoch\n\u001b[1;32m     27\u001b[0m               ,verbose=1, validation_data=(X_valid, Y_valid))\n","\u001b[0;32m<ipython-input-36-fd7643be6177>\u001b[0m in \u001b[0;36mcnn\u001b[0;34m(img_rows, img_cols, color_type)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;31m## CNN 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcolor_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_rows\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_cols\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mBatchNormalization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConvolution2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mactivation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'same'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/training/tracking/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    515\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_self_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/sequential.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, layer)\u001b[0m\n\u001b[1;32m    206\u001b[0m           \u001b[0;31m# and create the node connecting the current layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    207\u001b[0m           \u001b[0;31m# to the input layer we just created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m           \u001b[0mlayer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_in_functional_construction_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m       return self._functional_construction_call(inputs, args, kwargs,\n\u001b[0;32m--> 952\u001b[0;31m                                                 input_list)\n\u001b[0m\u001b[1;32m    953\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m     \u001b[0;31m# Maintains info about the `Layer.call` stack.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_functional_construction_call\u001b[0;34m(self, inputs, args, kwargs, input_list)\u001b[0m\n\u001b[1;32m   1089\u001b[0m         \u001b[0;31m# Check input assumptions set after layer building, e.g. input shape.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1090\u001b[0m         outputs = self._keras_tensor_symbolic_call(\n\u001b[0;32m-> 1091\u001b[0;31m             inputs, input_masks, args, kwargs)\n\u001b[0m\u001b[1;32m   1092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1093\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_keras_tensor_symbolic_call\u001b[0;34m(self, inputs, input_masks, args, kwargs)\u001b[0m\n\u001b[1;32m    820\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras_tensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mKerasTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_signature\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    821\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 822\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    823\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    824\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_infer_output_signature\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_masks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m_infer_output_signature\u001b[0;34m(self, inputs, args, kwargs, input_masks)\u001b[0m\n\u001b[1;32m    861\u001b[0m           \u001b[0;31m# TODO(kaftan): do we maybe_build here, or have we already done it?\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    862\u001b[0m           \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 863\u001b[0;31m           \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    864\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle_activity_regularization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    246\u001b[0m       \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marray_ops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_causal_padding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 248\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_convolution_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    249\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    250\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/util/dispatch.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    199\u001b[0m     \u001b[0;34m\"\"\"Call target, and fall back on dispatchers if there is a TypeError.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    200\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 201\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    202\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m       \u001b[0;31m# Note: convert_to_eager_tensor currently raises a ValueError, not a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_v2\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   1018\u001b[0m       \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1019\u001b[0m       \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1020\u001b[0;31m       name=name)\n\u001b[0m\u001b[1;32m   1021\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36mconvolution_internal\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name, call_from_convolution, num_spatial_dims)\u001b[0m\n\u001b[1;32m   1148\u001b[0m           \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1149\u001b[0m           \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1150\u001b[0;31m           name=name)\n\u001b[0m\u001b[1;32m   1151\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1152\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mchannel_index\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/nn_ops.py\u001b[0m in \u001b[0;36m_conv2d_expanded_batch\u001b[0;34m(input, filters, strides, padding, data_format, dilations, name)\u001b[0m\n\u001b[1;32m   2602\u001b[0m         \u001b[0mdata_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata_format\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2603\u001b[0m         \u001b[0mdilations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdilations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2604\u001b[0;31m         name=name)\n\u001b[0m\u001b[1;32m   2605\u001b[0m   return squeeze_batch_dims(\n\u001b[1;32m   2606\u001b[0m       \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/ops/gen_nn_ops.py\u001b[0m in \u001b[0;36mconv2d\u001b[0;34m(input, filter, strides, padding, use_cudnn_on_gpu, explicit_paddings, data_format, dilations, name)\u001b[0m\n\u001b[1;32m    971\u001b[0m                   \u001b[0mpadding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpadding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_cudnn_on_gpu\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    972\u001b[0m                   \u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mexplicit_paddings\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 973\u001b[0;31m                   data_format=data_format, dilations=dilations, name=name)\n\u001b[0m\u001b[1;32m    974\u001b[0m   \u001b[0m_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_outputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    975\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0m_execute\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmust_record_gradient\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    748\u001b[0m       op = g._create_op_internal(op_type_name, inputs, dtypes=None,\n\u001b[1;32m    749\u001b[0m                                  \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 750\u001b[0;31m                                  attrs=attr_protos, op_def=op_def)\n\u001b[0m\u001b[1;32m    751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    752\u001b[0m     \u001b[0;31m# `outputs` is returned as a separate return value so that the output\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m    590\u001b[0m     return super(FuncGraph, self)._create_op_internal(  # pylint: disable=protected-access\n\u001b[1;32m    591\u001b[0m         \u001b[0mop_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtypes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_def\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 592\u001b[0;31m         compute_device)\n\u001b[0m\u001b[1;32m    593\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mcapture\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_op_internal\u001b[0;34m(self, op_type, inputs, dtypes, input_types, name, attrs, op_def, compute_device)\u001b[0m\n\u001b[1;32m   3534\u001b[0m           \u001b[0minput_types\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_types\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3535\u001b[0m           \u001b[0moriginal_op\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_default_original_op\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3536\u001b[0;31m           op_def=op_def)\n\u001b[0m\u001b[1;32m   3537\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_create_op_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mret\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompute_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcompute_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3538\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mret\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, node_def, g, inputs, output_types, control_inputs, input_types, original_op, op_def)\u001b[0m\n\u001b[1;32m   2014\u001b[0m         \u001b[0mop_def\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_op_def\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2015\u001b[0m       self._c_op = _create_c_op(self._graph, node_def, inputs,\n\u001b[0;32m-> 2016\u001b[0;31m                                 control_input_ops, op_def)\n\u001b[0m\u001b[1;32m   2017\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_str\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[0;31m# pylint: enable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_create_c_op\u001b[0;34m(graph, node_def, inputs, control_inputs, op_def)\u001b[0m\n\u001b[1;32m   1854\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mInvalidArgumentError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1855\u001b[0m     \u001b[0;31m# Convert to ValueError for backwards compatibility.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1856\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1857\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1858\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mc_op\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Negative dimension size caused by subtracting 3 from 1 for '{{node conv2d_11/Conv2D}} = Conv2D[T=DT_FLOAT, data_format=\"NHWC\", dilations=[1, 1, 1, 1], explicit_paddings=[], padding=\"VALID\", strides=[1, 1, 1, 1], use_cudnn_on_gpu=true](Placeholder, conv2d_11/Conv2D/ReadVariableOp)' with input shapes: [?,1,64,64], [3,3,64,32]."]}]},{"cell_type":"code","metadata":{"id":"706DrviXznVM"},"source":[""],"execution_count":null,"outputs":[]}]}