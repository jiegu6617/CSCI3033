{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"train_all_vgg.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","metadata":{"id":"93wjqQJ38KqZ"},"source":["import os\n","import random\n","import numpy as np\n","import pandas as pd \n","from skimage import io\n","from skimage import color\n","from PIL import Image\n","from IPython.display import display\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from dask.array.image import imread\n","# from dask import bag, threaded\n","from dask.diagnostics import ProgressBar\n","import cv2\n","from sklearn.model_selection import train_test_split\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","\n","\n","\n","import keras\n","from keras.models import Sequential\n","from keras.layers import Dropout, Flatten, Dense\n","from keras.layers import Flatten,Dropout\n","from keras.layers import Conv2D, MaxPooling2D\n","from keras.utils import to_categorical\n","from keras.preprocessing import image \n","from keras.layers.normalization import BatchNormalization\n","from keras import optimizers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uOazoOem8O5_"},"source":["X_train=np.load('/content/drive/MyDrive/deep_learning_project/X_train.npy')\n","X_test=np.load('/content/drive/MyDrive/deep_learning_project/X_test.npy')\n","y_train=np.load('/content/drive/MyDrive/deep_learning_project/y_train.npy')\n","y_test=np.load('/content/drive/MyDrive/deep_learning_project/y_test.npy')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQzLR2cF8PQg"},"source":["\n","## Defining the input\n","\n","from keras.layers import Input\n","vgg16_input = Input(shape = (224, 224, 3), name = 'Image_input')\n","\n","\n","## The VGG model\n","\n","from keras.applications.vgg16 import VGG16, preprocess_input\n","\n","#Get back the convolutional part of a VGG network trained on ImageNet\n","model_vgg16_conv = VGG16(weights='imagenet', include_top=False, input_tensor = vgg16_input)\n","model_vgg16_conv.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"G8CI2iBJ8Vz7"},"source":["#Use the generated model \n","from keras.models import Model\n","\n","\n","output_vgg16_conv = model_vgg16_conv(vgg16_input)\n","\n","#Add the fully-connected layers \n","\n","x = Flatten(name='flatten')(output_vgg16_conv)\n","x = Dense(4096, activation='relu', name='fc1')(x)\n","x = Dense(4096, activation='relu', name='fc2')(x)\n","x = Dense(10, activation='softmax', name='predictions')(x)\n","\n","vgg16_pretrained = Model(vgg16_input, x)\n","vgg16_pretrained.summary()\n","\n","# Compile CNN model\n","sgd = optimizers.SGD(lr = 0.001)\n","vgg16_pretrained.compile(loss='categorical_crossentropy',optimizer = sgd,metrics=['accuracy'])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-FHEIiRs8aHH"},"source":["\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint,EarlyStopping\n","\n","checkpointer = ModelCheckpoint('vgg_weights_aug_alltrained.hdf5', verbose=1, save_best_only=True)\n","earlystopper = EarlyStopping(monitor='val_loss', patience=10, verbose=1)\n","\n","\n","datagen = ImageDataGenerator(\n","    height_shift_range=0.5,\n","    width_shift_range = 0.5,\n","    zoom_range = 0.5,\n","    rotation_range=30\n","        )\n","#datagen.fit(X_train)\n","data_generator = datagen.flow(X_train, y_train, batch_size = 64)\n","\n","# Fits the model on batches with real-time data augmentation:\n","vgg16_model = vgg16_pretrained.fit_generator(data_generator,steps_per_epoch = len(X_train) / 64, callbacks=[checkpointer, earlystopper],\n","                                                            epochs = 25, verbose = 1, validation_data = (X_test, y_test))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lvBMfk-t8dwL"},"source":["fig, axes = plt.subplots(1, 2, figsize = (10, 5))\n","axes[0].plot(range(1, len(vgg16_pretrained.history.history['accuracy']) + 1), vgg16_pretrained.history.history['accuracy'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Accuracy')\n","axes[0].plot(range(1, len(vgg16_pretrained.history.history['val_accuracy']) + 1), vgg16_pretrained.history.history['val_accuracy'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Accuracy')\n","axes[0].set_xlabel('Epochs', fontsize = 14)\n","axes[0].set_ylabel('Accuracy',fontsize = 14)\n","axes[0].set_title('CNN Dropout Accuracy Trainig VS Testing', fontsize = 14)\n","axes[0].legend(loc = 'best')\n","axes[1].plot(range(1, len(vgg16_pretrained.history.history['loss']) + 1), vgg16_pretrained.history.history['loss'], linestyle = 'solid', marker = 'o', color = 'crimson', label = 'Training Loss')\n","axes[1].plot(range(1, len(vgg16_pretrained.history.history['val_loss']) + 1), vgg16_pretrained.history.history['val_loss'], linestyle = 'solid', marker = 'o', color = 'dodgerblue', label = 'Testing Loss')\n","axes[1].set_xlabel('Epochs', fontsize = 14)\n","axes[1].set_ylabel('Loss',fontsize = 14)\n","axes[1].set_title('CNN Dropout Loss Trainig VS Testing', fontsize = 14)\n","axes[1].legend(loc = 'best')"],"execution_count":null,"outputs":[]}]}