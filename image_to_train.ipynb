{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "image_to_train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "4L4hnKZQgtwl"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd \n",
        "from skimage import io\n",
        "from skimage import color\n",
        "from PIL import Image\n",
        "from IPython.display import display\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from dask.array.image import imread\n",
        "# from dask import bag, threaded\n",
        "from dask.diagnostics import ProgressBar\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "\n",
        "\n",
        "\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Flatten, Dense\n",
        "from keras.layers import Flatten,Dropout\n",
        "from keras.layers import Conv2D, MaxPooling2D\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing import image \n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras import optimizers"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXMr-aSDg73d"
      },
      "source": [
        "driver_details = pd.read_csv('/content/drive/MyDrive/deep_learning_project/input/driver_imgs_list.csv',na_values='na')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5twtntOLhAaB",
        "outputId": "44ff3981-ab34-425f-b0b3-da4519ca52bc"
      },
      "source": [
        "train_image = []\n",
        "image_label = []\n",
        "\n",
        "\n",
        "for i in range(10):\n",
        "    print('now we are in the folder C',i)\n",
        "    imgs = os.listdir(\"/content/drive/MyDrive/deep_learning_project/input/train/c\"+str(i))\n",
        "    for j in range(len(imgs)):\n",
        "    #for j in range(100):\n",
        "        img_name = \"/content/drive/MyDrive/deep_learning_project/input/train/c\"+str(i)+\"/\"+imgs[j]\n",
        "        img = cv2.imread(img_name)\n",
        "        #img = color.rgb2gray(img)\n",
        "        img = img[50:,120:-50]\n",
        "        img = cv2.resize(img,(224,224))\n",
        "        label = i\n",
        "        driver = driver_details[driver_details['img'] == imgs[j]]['subject'].values[0]\n",
        "        train_image.append([img,label,driver])\n",
        "        image_label.append(i)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "now we are in the folder C 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AwZGDDMYhCvG"
      },
      "source": [
        "import random\n",
        "random.shuffle(train_image)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hCI1IkE0hEmX"
      },
      "source": [
        "driv_selected = ['p050', 'p015', 'p022', 'p056']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SizlJFPGhH_s"
      },
      "source": [
        "## Splitting the train and test\n",
        "\n",
        "X_train= []\n",
        "y_train = []\n",
        "X_test = []\n",
        "y_test = []\n",
        "D_train = []\n",
        "D_test = []\n",
        "\n",
        "for features,labels,drivers in train_image:\n",
        "    if drivers in driv_selected:\n",
        "        X_test.append(features)\n",
        "        y_test.append(labels)\n",
        "        D_test.append(drivers)\n",
        "    \n",
        "    else:\n",
        "        X_train.append(features)\n",
        "        y_train.append(labels)\n",
        "        D_train.append(drivers)\n",
        "    \n",
        "print (len(X_train),len(X_test))\n",
        "print (len(y_train),len(y_test))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RqcnghM0hKMI"
      },
      "source": [
        "X_train = np.array(X_train).reshape(-1,224,224,3)\n",
        "X_test = np.array(X_test).reshape(-1,224,224,3)\n",
        "y_train = to_categorical(y_train)\n",
        "y_test = to_categorical(y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rE0vxceyhKiF"
      },
      "source": [
        "np.save('X_train.npy', X_train)\n",
        "np.save('X_test.npy', X_test)\n",
        "np.save('y_train.npy', y_train)\n",
        "np.save('y_test.npy', y_test)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}